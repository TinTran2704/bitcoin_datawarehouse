{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93919433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTEBOOK CELL 1 - Setup and Imports\n",
    "import logging\n",
    "import os\n",
    "import traceback\n",
    "from typing import Dict, List, Any\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Setup logging for notebook\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Your imports here\n",
    "from ..pull_raw.utils import get_tables_to_sync\n",
    "from data_integration.utils.utils import get_abspath\n",
    "from data_integration.utils.worker.dune_extractor import DuneExtractor\n",
    "from data_integration.utils.worker.dune_to_pg_worker import DuneToPgWorker\n",
    "from data_integration.utils.worker.pg_loader import PgLoader\n",
    "from data_integration.arguments import FULL_REFRESH, INCREMENTAL_VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc46394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTEBOOK CELL 2 - Configuration\n",
    "TARGET_SCHEMA_NAME = 'bitcoin'\n",
    "\n",
    "# Database connection (replace with your connection details)\n",
    "DATABASE_URL = \"postgresql://username:password@localhost:5432/database_name\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# Your table metadata configuration\n",
    "table_meta_data = {\n",
    "    # Your table configuration here\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5599730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTEBOOK CELL 3 - Initialize Components\n",
    "# Initialize Dune extractor\n",
    "dune_extractor = DuneExtractor(api_key=os.environ.get('DUNE_API_KEY'))\n",
    "\n",
    "print(\"‚úÖ Dune extractor initialized\")\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# NOTEBOOK CELL 4 - Load Table Configuration\n",
    "# Load tables to sync\n",
    "tables_to_sync = get_tables_to_sync(table_meta_data)\n",
    "print(f\"Found {len(tables_to_sync)} tables to sync:\")\n",
    "for table in tables_to_sync:\n",
    "    print(f\"  - {table.get('name')} (sync_type: {table.get('sync_type')})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072af2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTEBOOK CELL 5 - Process Each Table\n",
    "with engine.connect() as connection:\n",
    "    # Initialize worker\n",
    "    dune_to_pg_worker = DuneToPgWorker(\n",
    "        dune_extractor=dune_extractor,\n",
    "        target_schema_name=TARGET_SCHEMA_NAME,\n",
    "        target_table=\"\",  # Will be updated per table\n",
    "        target_con=connection,\n",
    "    )\n",
    "    \n",
    "    # Process tables\n",
    "    for i, table in enumerate(tables_to_sync, 1):\n",
    "        table_name = table.get('name')\n",
    "        query_id = table.get('id')\n",
    "        sync_type = table.get('sync_type')\n",
    "        source_unique_keys = table.get('source_unique_keys', ['id'])\n",
    "        incremental_column = table.get('incremental_column', 'updated_at')\n",
    "        \n",
    "        print(f\"\\n[{i}/{len(tables_to_sync)}] Processing: {table_name}\")\n",
    "        print(f\"Query ID: {query_id}, Sync Type: {sync_type}\")\n",
    "        \n",
    "        # Update target table for worker\n",
    "        dune_to_pg_worker.target_table = table_name\n",
    "        \n",
    "        try:\n",
    "            if sync_type == 'full_refresh':\n",
    "                print(\"üîÑ Running full refresh...\")\n",
    "                dune_to_pg_worker.run(\n",
    "                    query_id=query_id,\n",
    "                    query_parameters=table.get('query_parameters'),\n",
    "                    source_unique_keys=source_unique_keys,\n",
    "                    load_strategy=FULL_REFRESH,\n",
    "                    max_wait_time=300\n",
    "                )\n",
    "                \n",
    "            elif sync_type is None or sync_type == 'sync_incremental':\n",
    "                print(\"üîÑ Running incremental sync...\")\n",
    "                \n",
    "                # Get last incremental value\n",
    "                pg_loader = PgLoader(\n",
    "                    connection=connection,\n",
    "                    schema_name=TARGET_SCHEMA_NAME,\n",
    "                    table_name=table_name\n",
    "                )\n",
    "                last_value = pg_loader.get_max_value(incremental_column)\n",
    "                \n",
    "                if last_value is None:\n",
    "                    print(\"No previous data found, running full refresh...\")\n",
    "                    load_strategy = FULL_REFRESH\n",
    "                    query_parameters = None\n",
    "                else:\n",
    "                    print(f\"Last incremental value: {last_value}\")\n",
    "                    load_strategy = INCREMENTAL_VALUE\n",
    "                    query_parameters = str(last_value)\n",
    "                \n",
    "                dune_to_pg_worker.run(\n",
    "                    query_id=query_id,\n",
    "                    query_parameters=query_parameters,\n",
    "                    source_unique_keys=source_unique_keys,\n",
    "                    incremental_column=incremental_column,\n",
    "                    incremental_value=last_value,\n",
    "                    load_strategy=load_strategy,\n",
    "                    max_wait_time=300\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(f'Invalid sync_type \"{sync_type}\"')\n",
    "                \n",
    "            print(f\"‚úÖ Successfully processed: {table_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to process {table_name}: {e}\")\n",
    "            print(traceback.format_exc())\n",
    "            # Continue with next table\n",
    "            continue\n",
    "            \n",
    "print(\"\\nüéâ All tables processed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3575fa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTEBOOK CELL 6 - Verify Results (Optional)\n",
    "# Check record counts for each table\n",
    "with engine.connect() as connection:\n",
    "    print(\"\\nüìä Table Record Counts:\")\n",
    "    for table in tables_to_sync:\n",
    "        table_name = table.get('name')\n",
    "        try:\n",
    "            pg_loader = PgLoader(\n",
    "                connection=connection,\n",
    "                schema_name=TARGET_SCHEMA_NAME,\n",
    "                table_name=table_name\n",
    "            )\n",
    "            count = pg_loader.get_record_count()\n",
    "            print(f\"  {table_name}: {count:,} records\")\n",
    "        except Exception as e:\n",
    "            print(f\"  {table_name}: Error getting count - {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
