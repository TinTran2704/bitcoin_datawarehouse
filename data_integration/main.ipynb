{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93919433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTEBOOK CELL 1 - Setup and Imports\n",
    "import logging\n",
    "import os\n",
    "import traceback\n",
    "from typing import Dict, List, Any\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "# Setup logging for notebook\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Your imports here\n",
    "from pull_raw.utils import get_tables_to_sync, start_job, end_job\n",
    "from utils.utils import get_abspath\n",
    "from utils.worker.dune_extractor import DuneExtractor\n",
    "from utils.worker.dune_to_pg_worker import DuneToPgWorker\n",
    "from utils.worker.pg_loader import PgLoader\n",
    "from datetime import datetime\n",
    "#from arguments import FULL_REFRESH, INCREMENTAL_VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbc46394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTEBOOK CELL 2 - Configuration\n",
    "TARGET_SCHEMA_NAME = 'bitcoin'\n",
    "\n",
    "# Database connection (replace with your connection details)\n",
    "DATABASE_URL = \"postgresql://postgres:tranbaotin@localhost:5432/postgres\"\n",
    "engine = create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5599730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTEBOOK CELL 3 - Initialize Components\n",
    "\n",
    "tables_to_sync = get_tables_to_sync()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e66be30",
   "metadata": {},
   "outputs": [],
   "source": [
    "name, id, tar_tbl, pkey = list(),list(),list(),list()\n",
    "for index, row in tables_to_sync.iterrows():\n",
    "    name.append(row['name'])\n",
    "    id.append(row['id'])\n",
    "    tar_tbl.append(row['target_table'])\n",
    "    pkey.append(row['p_key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ea1a8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bitcoin_inputs',\n",
       " 'bitcoin_output',\n",
       " 'prices_usd',\n",
       " 'bitcoin_transactions',\n",
       " 'bitcoin_block']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af5f585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "enum = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "36515c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C·∫≠p nh·∫≠t th√†nh c√¥ng cho job: bitcoin_inputs\n",
      "Query 2177353 executed. Execution ID: 01K6G3YQM3Q6MMFQY5Q1PQFJ1S\n",
      "Waiting... (state: QUERY_STATE_EXECUTING)\n",
      "Data crawled successfully!\n",
      "Retrieved 100000 rows\n"
     ]
    }
   ],
   "source": [
    "# Initialize Dune extractor\n",
    "dune_extractor = DuneExtractor(api_key=\"Rq8roupIKKIZ9Iw5lFqNuqsgUAywgtvp\")\n",
    "start_job(name[enum])\n",
    "# Execute the query and get execution ID\n",
    "execution_id = dune_extractor.execute_query(\n",
    "    query_id=id[enum],\n",
    "    parameters=\"2025-01-01\"\n",
    ")\n",
    "\n",
    "# Get the results\n",
    "raw_data = dune_extractor.get_results(\n",
    "    execution_id=execution_id,\n",
    "    max_wait_time=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82e4f4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(raw_data)\n",
    "df[\"ETL_updated_ts\"] = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "098bfc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C·∫≠p nh·∫≠t th√†nh c√¥ng cho job: bitcoin_inputs\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as connection:\n",
    "    df.to_sql(\n",
    "        name=tar_tbl[enum],\n",
    "        con=connection,\n",
    "        schema=TARGET_SCHEMA_NAME,\n",
    "        if_exists='append',\n",
    "        index=False,\n",
    "        method='multi'\n",
    "    )\n",
    "    \n",
    "end_job(name[enum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072af2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Dune extractor\n",
    "dune_extractor = DuneExtractor(api_key=\"Rq8roupIKKIZ9Iw5lFqNuqsgUAywgtvp\")\n",
    "\n",
    "# NOTEBOOK CELL 5 - Process Each Table\n",
    "for index, row in tables_to_sync.iterrows():\n",
    "    start_job(row['name'])\n",
    "    with engine.connect() as connection:\n",
    "        # Initialize worker\n",
    "        dune_to_pg_worker = DuneToPgWorker(\n",
    "            dune_extractor=dune_extractor,\n",
    "            target_schema_name=TARGET_SCHEMA_NAME,\n",
    "            target_table=\"\",  # Will be updated per table\n",
    "            target_con=connection,\n",
    "        )\n",
    "        \n",
    "        # Process tables\n",
    "        for i, table in enumerate(tables_to_sync, 1):\n",
    "            table_name = row['target_table']\n",
    "            query_id = row['id']\n",
    "            source_unique_keys = row['p_key']\n",
    "            \n",
    "            print(f\"\\n[{i}/{len(tables_to_sync)}] Processing: {table_name}\")\n",
    "            print(f\"Query ID: {query_id}, Sync Type: {sync_type}\")\n",
    "            \n",
    "            # Update target table for worker\n",
    "            dune_to_pg_worker.target_table = table_name\n",
    "            \n",
    "            try:\n",
    "                if sync_type == 'full_refresh':\n",
    "                    print(\"üîÑ Running full refresh...\")\n",
    "                    dune_to_pg_worker.run(\n",
    "                        query_id=query_id,\n",
    "                        query_parameters=table.get('query_parameters'),\n",
    "                        source_unique_keys=source_unique_keys,\n",
    "                        load_strategy=FULL_REFRESH,\n",
    "                        max_wait_time=300\n",
    "                    )\n",
    "                    \n",
    "                elif sync_type is None or sync_type == 'sync_incremental':\n",
    "                    print(\"üîÑ Running incremental sync...\")\n",
    "                    \n",
    "                    if last_value is None:\n",
    "                        print(\"No previous data found, running full refresh...\")\n",
    "                        load_strategy = FULL_REFRESH\n",
    "                        query_parameters = None\n",
    "                    else:\n",
    "                        print(f\"Last incremental value: {last_value}\")\n",
    "                        load_strategy = INCREMENTAL_VALUE\n",
    "                        query_parameters = str(last_value)\n",
    "                    \n",
    "                    dune_to_pg_worker.run(\n",
    "                        query_id=query_id,\n",
    "                        query_parameters=query_parameters,\n",
    "                        source_unique_keys=source_unique_keys,\n",
    "                        incremental_column=incremental_column,\n",
    "                        incremental_value=last_value,\n",
    "                        load_strategy=load_strategy,\n",
    "                        max_wait_time=300\n",
    "                    )\n",
    "                else:\n",
    "                    raise ValueError(f'Invalid sync_type \"{sync_type}\"')\n",
    "                    \n",
    "                print(f\"‚úÖ Successfully processed: {table_name}\")\n",
    "                end_job(row['name'])\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Failed to process {table_name}: {e}\")\n",
    "                print(traceback.format_exc())\n",
    "                # Continue with next table\n",
    "                continue\n",
    "                \n",
    "    print(\"\\nüéâ All tables processed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
